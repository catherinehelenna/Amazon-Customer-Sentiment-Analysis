{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-20 16:38:28.874356: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-02-20 16:38:28.874425: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-02-20 16:38:28.874429: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-02-20 16:38:28.874735: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-02-20 16:38:28.875022: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "2024-02-20 16:38:29.450405: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "loaded_model = load_model('improved_model_tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am dissapointed, hate it.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  reviews.text\n",
       "0  I am dissapointed, hate it."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data inference => for example negative sentiment\n",
    "data_inf = {'reviews.text':'I am dissapointed, hate it.'}\n",
    "\n",
    "# insert into dataframe\n",
    "data_inf = pd.DataFrame([data_inf])\n",
    "data_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/catherinemulyadi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column stopwords\n",
    "stopwords = ['haven', 'only', 'why', 'o', 'his', 'won', 'how', \"weren't\", 'under', \"mustn't\", 'nor', 'which', 'himself', \"you're\", \"aren't\", 'shouldn', 'below', 'over', 'up', \"shan't\", 'than', \"it's\", 'your', 'against', 'down', \"shouldn't\", \"you've\", 'what', 'in', 'wasn', 'them', 'that', 'herself', 'not', 'does', 'had', 'for', 'during', 'further', 'him', 'itself', 'tv', 'isn', \"couldn't\", 'once', 'one', 'tablet', 'doesn', \"wouldn't\", 't', 'ourselves', 'before', 'app', 'until', 'while', 'couldn', 'an', 'fire', 'our', 'into', 'about', 'because', 'most', 'who', 'me', 'have', 'themselves', 'these', 'when', 'mustn', 'kid', 'ain', 'and', 'yours', 'do', 'i', \"hasn't\", 'yourselves', 'has', \"she's\", 'having', 'to', 've', 'again', 'their', 'some', 'own', 'whom', 'her', 'will', 'we', 'at', 'wouldn', 'other', 'needn', 'or', 'between', 'shan', 'don', 'being', 'd', 'same', 'by', 'with', 'm', 'as', 'from', 'hers', \"should've\", 's', \"you'll\", \"mightn't\", 'all', 'off', 'are', 'very', 'those', 'alexa', 'where', 'didn', 'mightn', 'few', 'but', 'can', 'am', \"don't\", 'hasn', 'hadn', 'weren', 'out', 'was', 'doing', \"you'd\", 'on', 'did', \"didn't\", 'it', \"haven't\", \"needn't\", 'no', \"isn't\", \"won't\", 'you', 'after', 'then', 'so', 'my', 'she', 'y', 'each', 'such', 'amazon', 'of', 'there', 'been', 'yourself', 'this', 'if', \"hadn't\", 'be', 'ma', 'just', 'the', 'its', 'more', 're', 'is', 'here', 'kindle', 'any', 'aren', 'echo', 'through', 'ours', 'theirs', 'were', \"doesn't\", 'now', \"that'll\", 'should', 'a', 'above', 'they', \"wasn't\", 'myself', 'both', 'too', 'll', 'he']\n",
    "\n",
    "# nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for text preporcessing\n",
    "def text_preprocessing(filtered_dataset, stopwords):\n",
    "    # Convert text in 'sentiment.value' column to lowercase\n",
    "    text = filtered_dataset['reviews.text'].apply(lambda x: x.lower())\n",
    "\n",
    "    # Mention removal\n",
    "    text = text.apply(lambda x: re.sub(\"@[A-Za-z0-9_]+\", \" \", x))\n",
    "\n",
    "    # Hashtags removal\n",
    "    text = text.apply(lambda x: re.sub(\"#[A-Za-z0-9_]+\", \" \", x))\n",
    "\n",
    "    # Newline removal (\\n)\n",
    "    text = text.apply(lambda x: re.sub(r\"\\\\n\", \" \", x))\n",
    "\n",
    "    # Whitespace removal\n",
    "    text = text.apply(lambda x: x.strip())\n",
    "\n",
    "    # URL removal\n",
    "    text = text.apply(lambda x: re.sub(r\"http\\S+\", \" \", x))\n",
    "    text = text.apply(lambda x: re.sub(r\"www.\\S+\", \" \", x))\n",
    "\n",
    "    # Non-letter removal (such as emoticon, symbol (like μ, $, 兀), etc\n",
    "    text = text.apply(lambda x: re.sub(\"[^A-Za-z\\s']\", \" \", x))\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = text.apply(lambda x: word_tokenize(x))\n",
    "\n",
    "    # Stopwords removal\n",
    "    tokens = tokens.apply(lambda x: [word for word in x if word not in stopwords])\n",
    "\n",
    "    # # Stemming\n",
    "    # stemmer = PorterStemmer()\n",
    "    # tokens = tokens.apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "\n",
    "    # Combining Tokens\n",
    "    text = tokens.apply(lambda x: ' '.join(x))\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.text.processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am dissapointed, hate it.</td>\n",
       "      <td>dissapointed hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  reviews.text reviews.text.processed\n",
       "0  I am dissapointed, hate it.      dissapointed hate"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implementasi fungsi\n",
    "data_inf['reviews.text.processed'] = text_preprocessing(data_inf, stopwords)\n",
    "\n",
    "# show dataframe\n",
    "data_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definisi X\n",
    "X_inf = data_inf['reviews.text.processed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "# Perform inference using the loaded model\n",
    "predictions = loaded_model.predict(X_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment value is negative\n"
     ]
    }
   ],
   "source": [
    "# Assuming the predictions are stored in a NumPy array 'predictions'\n",
    "prediction_array = np.array(predictions)\n",
    "\n",
    "# Find the index of the maximum value\n",
    "max_index = np.argmax(prediction_array)\n",
    "\n",
    "# Define sentiment labels\n",
    "sentiment_labels = [\"negative\", \"neutral\", \"positive\"]\n",
    "\n",
    "# Assign sentiment label based on the index of the maximum value\n",
    "sentiment = sentiment_labels[max_index]\n",
    "\n",
    "print(\"Sentiment value is\", sentiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
